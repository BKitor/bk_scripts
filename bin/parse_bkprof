#!/usr/bin/python3

import logging
import math
import sys
import re
import argparse
import csv

alg_exp_fmt_dict = {
    "k-ary": {
        "root": "arrive_at_ktree",
        "points": [
            "finish_intra_reduce",
            "register_at_ss",
            "reduce_pbuf",
            "get_parent_rank",
            "send_parent_data",
            "get_leader_of_tree",
            "finish_inter_bcast",
            "reset_remote_ss",
            "leave_intra_bcast",
        ],
    },
    "k-ary-pipe": {
        "root": "ktree_pipeline_arrive",
        "points": [
            "finish_intra_reduce",
            "start_new_segment",
            "leave_new_seg_wait",
            "starting_new_sync_round",
            "synced_at_ss",
            "start_postbuf_reduce",
            "leave_postbuf_reduce",
            "reset_remote_ss",
            "got_parent_rank",
            "sent_parent_rank",
            "leave_main_loop",
            "leave_cleanup_wait",
            "final_cleanup_wait",
            "ktree_pipeline_leave",
        ],
    },
    "k-ary-fullpipe": {
        "root": "arrive_at_fullpipe",
        "points": [
            "start_new_segment",
            "leave_new_seg_wait",
            "finish_intra_reduce_seg",
            "starting_new_sync_round",
            "synced_at_ss",
            "start_postbuf_reduce",
            "leave_postbuf_reduce",
            "reset_remote_ss",
            "got_parent_rank",
            "sent_parent_rank",
            "leave_main_loop",
            "leave_cleanup_wait",
            "final_cleanup_wait",
            "ktree_fullpipe_leave",
        ],
    },
    "bk-rsa": {
        "root": "bkpap_rsa_start_algorithm",
        "points": [
            "bkpap_rsa_intra_reduce",
            "bkpap_rsa_get_arrival",
            "bkpap_rsa_aloc_tmp_bff",
            "bkpap_rsa_enter_early_exchange",
            "dplane_tag_early_p2p_wait_start",
            "dplane_tag_early_p2p_wait_end",
            "dplane_tag_early_p2p_reduce_end",
            "bkpap_rsa_leave_early_exchange",
            "bkpap_rsa_enter_late_exchange",
            "dplane_tag_late_p2p_wait_start",
            "dplane_tag_late_p2p_wait_end",
            "dplane_tag_late_p2p_reduce_end",
            "bkpap_rsa_leave_late_exchange",
            "bkpap_rsa_finish_rs",
            "bkpap_rsa_enter_sendrecv",
            "bkpap_rsa_leave_sendrecv",
            "bkpap_rsa_reset_ss",
            "bkpap_rsa_intra_bcast",
            "bkpap_rsa_end_algorithm",
        ],
    },
    "bk-rsa-comp": {
        "root": "bkpap_rsa_start_algorithm",
        "points": [
            "bkpap_rsa_intra_reduce",
            "bkpap_rsa_get_arrival",
            "bkpap_rsa_aloc_tmp_bff",
            "bkpap_rsa_finish_rs",
            "bkpap_rsa_enter_sendrecv",
            "bkpap_rsa_leave_sendrecv",
            "bkpap_rsa_reset_ss",
            "bkpap_rsa_intra_bcast",
            "bkpap_rsa_end_algorithm",
        ],
    },
    "base-rsa": {
        "root": "base_rsa_gpu_start_algorithm",
        "points": [
            "base_rsa_start_phase_1",
            "base_rsa_end_phase_1",
            "base_rsa_start_rs_sendrecv",
            "base_rsa_end_rs_sendrecv",
            "base_rsa_end_rs_reduce",
            "base_rsa_end_reduce_scatter",
            "base_rsa_start_ag_sendrecv",
            "base_rsa_end_ag_sendrecv",
            "base_rsa_end_allgather",
            "base_rsa_end_phase_4",
            "base_rsa_gpu_end_algorithm",
        ],
    },
    "bk-bin": {
        "root": "bkpap_bin_start",
        "points": [
                "bkpap_bin_intra_reduce",
                "bkpap_bin_get_arrival",
                "bkpap_bin_calc_tree",
                "bkpap_bin_recv_child",
                "bkpap_bin_send_parent",
                "bkpap_bin_inter_bcast",
                "bkpap_bin_intra_bcast",
                "bkpap_bin_end",
        ],
    },
    "bk-chain":{
        "root": "bkpap_chain_start",
        "points": [
            "bkpap_chain_intra_reduce",
            "bkpap_chain_recv_child",
            "bkpap_chain_send_parent",
            "bkpap_chain_local_reduce",
            "bkpap_chain_inter_bcast",
            "bkpap_chain_intra_bcast",
        ]
    }
}


parser = argparse.ArgumentParser()
parser.add_argument("FILE")
parser.add_argument("-n", type=int, required=True,
                    help="Number of ranks in process")
parser.add_argument("-s", type=int, required=True,
                    help="Number of samples per run")
parser.add_argument("-e", type=int, required=True,
                    help="Number of runs per job")
parser.add_argument("-w", type=int, default=0,
                    help="number of warmup runs (default 0)")
parser.add_argument("-a", type=str, required=True,
                    help=f"alg selection {list(alg_exp_fmt_dict.keys())}")
parser.add_argument("-d", action="store_true", default=False,
                    help="force output")
parser.add_argument("-l", action="store_true", default=False,
                    help="Print legacy style")
args = parser.parse_args()

if args.d:
    logging.getLogger().setLevel(logging.DEBUG)


if args.a not in alg_exp_fmt_dict:
    logging.error(
        f"{args.a} not a supported alg, try {alg_exp_fmt_dict.keys()}")
    exit()

exp_fmt = alg_exp_fmt_dict[args.a]

c = re.compile(
    r"^\[.+\]  BKPAP_PROFILE: (?P<time>\d+\.\d+) rank: (?P<rank>\d+) (?P<lbl>\w+)$")

timing_template = {
    k: 0.0 for k in exp_fmt["points"]
}

# array of experiments, each experiment is an array of ranks, each rank is a dict containing the sum of data points
master_dataset = [[timing_template.copy() for _ in range(args.n)]
                  for _ in range(args.e)]
# hold the preveous timing point for a rank
prev_time_arr = [0.0 for _ in range(args.n)]
# count the number of experiments for a rank
exp_count = [-1 for _ in range(args.n)]
# array to count the number of warmup itterations, not the most space efficient but it's easy to implement
warmup_count = [prev_time_arr.copy() for _ in range(args.e)]

total_runs = 0
maths_out = False
f_input = args.FILE
with open(f_input) as f:
    for line in f:
        m = c.search(line)
        if m is None:
            # logging.info(f"Mismach line {line}")
            continue
        if int(m.group("rank")) >= args.n:
            logging.error(f"Matched rank > -n : {line}")
            continue

        lbl = m.group("lbl")
        if lbl != exp_fmt["root"] and lbl not in exp_fmt["points"]:
            logging.error(f"matched profiling point with missing label {lbl}")

        if lbl == exp_fmt["root"]:
            total_runs += 1

    maths_out = (total_runs / args.n) == (args.e * args.s)
    if not maths_out:
        logging.error("Check failed")
        logging.error(
            f"Collected runs: {total_runs}, mpi_wsise: {args.n} /= {total_runs/args.n}")
        logging.error(
            f"samples per run: {args.s}, num experiments: {args.e} *= {args.s*args.e}")
        exit()

    f.seek(0)
    for line in f:
        m = c.search(line)
        commit_delta = True
        if m is not None and int(m.group("rank")) < args.n:
            msecs = (float(m.group("time"))*1e6)
            rank = int(m.group("rank"))
            lbl = m.group("lbl")
            delta = msecs - prev_time_arr[rank]
            prev_time_arr[rank] = msecs

            if lbl == exp_fmt["root"]:
                exp_count[rank] += 1

            exp = (math.floor((exp_count[rank])/args.s))

            if lbl == exp_fmt["root"]:
                if warmup_count[exp][rank] < args.w:
                    warmup_count[exp][rank] += 1

            commit_delta = warmup_count[exp][rank] >= args.w

            logging.info(
                f"warr: {warmup_count[exp][rank]} commit state: {commit_delta}")

            if not lbl == exp_fmt["root"] and commit_delta:
                master_dataset[exp][rank][lbl] += delta


def print_legacy_exps(args, tt, mdset):
    dict_writer = csv.DictWriter(sys.stdout, tt.keys())
    num_runs = args.s - args.w
    for experiment in mdset:
        print("")
        dict_writer.writeheader()
        for exp_row in experiment:
            avg_out = {k: v / num_runs for k, v in exp_row.items()}
            dict_writer.writerow(avg_out)
    print(f", num_runs, {num_runs}")


def print_exps(args, tt, mdset):
    dict_writer = csv.DictWriter(sys.stdout, tt.keys())
    dict_writer.writeheader()
    num_runs = args.s - args.w
    for experiment in mdset:
        exp_out_dict = {k: 0 for k in tt.keys()}
        for exp_row in experiment:
            for k in exp_row:
                exp_out_dict[k] += exp_row[k]/num_runs/args.n
        dict_writer.writerow(exp_out_dict)
    print(f", num_runs, {num_runs}")


if args.l:
    print_legacy_exps(args, timing_template, master_dataset)
else:
    print_exps(args, timing_template, master_dataset)
