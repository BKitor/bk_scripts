#!/usr/bin/python3

'''
Tool to quickly go from program output HVD/OMB -> csv
Designed to be easy to extend, just add new re modules with named groups

TODO:
    - Be abel to 'group by' multiple groups, make -g a comma seperated list of groups
'''


import argparse
import logging
import re
import csv
import sys

GPD = {
    "hvd_cpu": re.compile(r"^Number of CPUs: (?P<ncpu>\w+)$"),
    "hvd_gpu": re.compile(r"^Number of GPUs: (?P<ngpu>\w+)$"),
    "hcoll_en_sharp": re.compile(r"^HCOLL_ENABLE_SHARP=(?P<sharp>\d)$"),
    "ompi_hcoll_en": re.compile(r"^OMPI_MCA_coll_hcoll_enable=(?P<hcoll>\d)$"),
    "bkpap_prio": re.compile(r"^bkpapPrio: (?P<bkpap_prio>\d+)$"),
    "n_and_npernode": re.compile(r"^-n (?P<wsize>\d+) --npernode (?P<ppn>\d+)$"),
    "n_and_ppn": re.compile(r"^OSU_Allreduce GPU, --n (?P<wsize>\d+) --ppn (?P<ppn>\d+)$"),
    "omb_recmp_run": re.compile(r"^(?P<msize>\d+)\s+(?P<time>\d+\.\d+)$"),
    "mif": re.compile(r"# BK OSU Allreduce MIF (?P<mif>\d+\.\d+)?"),
    "ucc_prio": re.compile(r"^UCC prio: (?P<ucc_prio>\d+)$"),
    "ompi_pml": re.compile(r"^OMPI_pml (?P<pml>\w+)$"),
    "hvd_cycle_time": re.compile(r"^HOROVOD_CYCLE_TIME: (?P<hvd_cycle_time>\d+)$"),
    "osu_p2p_memloc": re.compile(r"^# Send Buffer on \w+ \((?P<sloc>\w+)\) and Receive Buffer on \w+ \((?P<rloc>\w+)\)$"),
    # misses 'Bi-Directinoal Bandwithd'
    "osu_p2p_type": re.compile(r"^# OSU MPI-CUDA (?P<type>[\w]+) Test v5\.\d+$"),
}
hvd_recmp_cpu = GPD["hvd_cpu"]
hvd_recmp_gpu = GPD["hvd_gpu"]

recmp_sharp_en = GPD["hcoll_en_sharp"]
recmp_hcoll_en = GPD["ompi_hcoll_en"]
recmp_wsize_ppn = GPD["n_and_npernode"]

omb_recmp_run = GPD["omb_recmp_run"]
omb_pap_recmp_mif = GPD["mif"]

hvd_recmp_base = [
    re.compile(r"^Model: (?P<model>\w+)$"),
    re.compile(r"^Batch size: (?P<bsize>\d+)$"),
    re.compile(
        r"^Total img/sec.* (?P<avg_perf>\d+\.\d) \+-(?P<avg_perf_err>\d+\.\d)$"),
]


def gen_match_help_str(recmp_dict):
    ret_str = "Available patterns:\n"
    max_len_str = max(map(lambda x: len(x), recmp_dict.keys()))
    for k, v in recmp_dict.items():
        ret_str += f'"{k:{max_len_str}}" : {v.pattern:s}\n'

    return ret_str


# TODO: Add fold-by functionality here
def parse_hvd_style(file_name, folds, recmp_arr):
    # assumes that each match will be fufilled before rematching
    logging.info(f"parse_hvd_style, file:{file_name}, folds: {folds}")
    logging.info(f"match_arr:{recmp_arr}")

    id_list_base = []
    for m in recmp_arr:
        id_list_base.extend(m.groupindex.keys())

    id_list = []
    for f in range(folds):
        id_list.extend([f"{id}_{f}" for id in id_list_base])

    logging.info(id_list_base)
    logging.info(id_list)

    csv_writer = csv.DictWriter(sys.stdout, id_list)
    csv_writer.writeheader()

    tmp_match_dict = {k: None for k in id_list_base}
    tmp_print_dict = {k: None for k in id_list}
    conut_match_sets = 0
    with open(file_name) as f:
        for line in f:
            # match line, extract info, and stuff in tmp_match_dict
            matches = map(lambda x: x.search(line), recmp_arr)
            for i, m in enumerate(matches):
                if m is None:
                    continue

                for k, v in recmp_arr[i].groupindex.items():
                    tmp_match_dict[k] = m.group(v)
                    logging.info(
                        f"added to tmp_match_dict:{tmp_match_dict.values()}")

            # if tmp_match_dict full, move to tmp_print_dict
            if None not in tmp_match_dict.values():
                logging.info(
                    f"filled tmp_match_dict:{tmp_match_dict.values()}")
                for k in tmp_match_dict:
                    tmp_print_dict[f"{k}_{conut_match_sets}"] = tmp_match_dict[k]
                    tmp_match_dict[k] = None
                conut_match_sets += 1

            # logging.info(f"{tmp_print_dict.values()}")
            if None not in tmp_print_dict.values():
                logging.info(
                    f"filled tmp_print_dict:{tmp_match_dict.values()}")
                csv_writer.writerow(tmp_print_dict)
                for k in tmp_print_dict:
                    tmp_print_dict[k] = None
                conut_match_sets = 0


def parse_omb_style_file(file_name, exp_recmp_arr, line_recmp):
    '''
    return 2 elements
    exp_names -> array of experiment names
    dat_dict -> dict for each message size to a dict of exp_name:time
    {"msize": {"exp_name" : "time" } }
    '''
    exp_name = ""
    dat_dict = {}
    exp_names = []
    track_matches_arr = [False for _ in exp_recmp_arr]
    with open(file_name) as f:
        for line in f:
            exp_matches = map(lambda x: x.search(line), exp_recmp_arr)
            m_dat = line_recmp.search(line)

            exp_match_list = list(exp_matches)

            if all(m is None for m in exp_match_list) and m_dat is None:
                continue

            for i, m in enumerate(exp_match_list):
                if m is None:
                    continue

                # the experiment matching shuold be thought thorugh a bit better tbh
                if track_matches_arr[i]:
                    logging.debug("Clearing exp_name")
                    track_matches_arr = [False for _ in exp_recmp_arr]
                    # if exp_name not in exp_names:
                    #     exp_names.append(exp_name)
                    exp_name = ""

                track_matches_arr[i] = True
                g_idx = exp_recmp_arr[i].groupindex

                for gname, idx in g_idx.items():
                    logging.debug(f"matched identifier {gname}:{m.group(idx)}")
                    exp_name += f"{gname}{m.group(idx)},"

                if all(track_matches_arr) and exp_name not in exp_names:
                    logging.debug(f"adding {exp_name} to exp_names")
                    exp_names.append(exp_name)

            if m_dat is None:
                logging.debug(exp_names)
                continue

            if m_dat.group(1) not in dat_dict:
                dat_dict[m_dat.group(1)] = {}

            logging.debug(
                f"matched datapoint {m_dat.group(1)}:{m_dat.group(2)}")
            dat_dict[m_dat.group(1)][exp_name] = m_dat.group(2)

    return exp_names, dat_dict


def print_exp_names_from_dat_dict(exp_names, dat_dict):
    # might want to cache this somewhere so that i'm not constatnly recalculating
    # point towards making this more class-based
    dat_arr = list(dat_dict.items())  # list of  ('msize', {'exp_name':'time'})
    dat_arr.sort(key=lambda x: int(x[0]))  # sort numericly by message size

    csv_headers = ["msize"]
    csv_headers.extend(exp_names)

    csv_writer = csv.DictWriter(sys.stdout, csv_headers)
    csv_writer.writeheader()

    for row in dat_arr:
        for exp_name in exp_names:  # error checking in case a run didn't complete
            if exp_name not in row[1]:
                row[1][exp_name] = None

        tmp_dict = {
            exp_name: row[1][exp_name] for exp_name in exp_names
        }
        tmp_dict["msize"] = row[0]
        csv_writer.writerow(tmp_dict)


def print_omb_by_num(num_folds, exp_names, dat_dict):
    num_tables = int(len(exp_names)/num_folds)

    for i in range(num_tables):
        fold_idx = i*num_folds
        cur_exp_names = exp_names[fold_idx:fold_idx+num_folds]
        print_exp_names_from_dat_dict(cur_exp_names, dat_dict)


def print_omb_by_group(fold_by, exp_names, dat_dict):
    '''
    This is hack that depends on fold_by being followed by , in expname
    This should work, unless I change the naming convention in parse_omb_style_file
    '''
    table_dict = {}

    for exp_name in exp_names:
        start_idx = exp_name.find(fold_by)
        end_idx = exp_name.find(",", start_idx)

        if exp_name[start_idx:end_idx] not in table_dict:
            table_dict[exp_name[start_idx:end_idx]] = []

        table_dict[exp_name[start_idx:end_idx]].append(exp_name)

    for exp_name_list in table_dict.values():
        print_exp_names_from_dat_dict(exp_name_list, dat_dict)


def parse_omb_style(file_name, exp_recmp_arr, line_recmp, num_folds=1, fold_by=""):
    '''
    exp_recmp_arr -> array of compiles re for parameter experiments, (bsize, nproc, SHArP on/off)
        used to generate names for each experiment column
    line_recmp -> line of measurement, i.e. the msize+time line in OMB (TODO: needs better explination)
    '''
    logging.info(f"parse_hvd_style, file:{file_name}")
    logging.info(f"exp_recmp_arr: {exp_recmp_arr}")
    logging.info(f"line_match: {line_recmp}")

    group_names = []
    for recmp in exp_recmp_arr:
        group_names.extend(recmp.groupindex.keys())
    logging.info(f"group_names: {group_names}")

    if (len(set(group_names)) != len(group_names)):
        logging.error(f"There are duplicates in group_names: {group_names}")
        exit()

    exp_names, dat_dict = parse_omb_style_file(
        file_name, exp_recmp_arr, line_recmp)

    logging.info(f"omb parse found experiment names {exp_names}")
    # logging.info(f"omb parse return data dict {dat_dict}")

    if fold_by:
        if fold_by not in group_names:
            logging.error(
                f"Could not find fold-by group: {fold_by} in {group_names}")
            exit()

        if not all(map(lambda exp_name: fold_by in exp_name, exp_names)):
            logging.error(
                f"Could not find fold-by group: {fold_by} in {exp_names}")
            exit()

        logging.info(f'folding by group "{fold_by}"')
        print_omb_by_group(fold_by, exp_names, dat_dict)
    else:
        logging.info(f'folding by count {num_folds}')
        print_omb_by_num(num_folds, exp_names, dat_dict)


def parse_inputs():
    parser = argparse.ArgumentParser(epilog=gen_match_help_str(
        GPD), formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("FILE")
    parser.add_argument("-d", "--debug", action="store_true",
                        help="Enable DEBUG level logging")
    parser.add_argument("-n", "--num-folds", type=int, default=1,
                        help="How many experiments to fold into the output")
    parser.add_argument("-g", "--fold-by", type=str,
                        help="Group tables by specified regex-group")
    parser.add_argument("-p", "--pattern-lst", type=str,
                        help="Comma sepperated list of features to match (eg: mif,ucc_prio,ppn,wsize)")

    parser.add_argument("--hvd-style", action="store_true",
                        help="Parse horovod style script")
    parser.add_argument("--cpu", action="store_true",
                        help="Parse horovod cpu runs")
    parser.add_argument("--gpu", action="store_true",
                        help="Parse horovod gpu runs")
    parser.add_argument("--omb-style", action="store_true",
                        help="Parse omb style script")
    # parser.add_argument("--pap", action="store_true",
    # help="Parse MIF varried tests (only OMB for now)")
    args = parser.parse_args()

    if args.num_folds < 1:
        logging.error(
            f"-n/--num-folds must be greater than 1, value given was {args.num_folds}")
        exit()

    if args.num_folds != 1 and args.fold_by:
        logging.error(
            "-n/--num-folds and -g/--group-by are incompatible, set one or the other")
        exit()

    if args.omb_style and args.hvd_style:
        logging.error(
            "--hvd-style and --omb-style are incompatible, set one or the other")
        exit()

    if not args.omb_style and not args.hvd_style:
        logging.error(
            "One of --hvd-style or --omb-style must be set")
        exit()

    return args


def get_patterns_from_str(pat_str):
    ret_arr = []
    pattern_arr = pat_str.split(",")
    for p in pattern_arr:
        if p not in GPD:
            logging.error(f"pattern {p} not found, exiting")
            exit()
        ret_arr.append(GPD[p])

    # logging.info(ret_arr)
    return ret_arr


def main():
    args = parse_inputs()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    if args.hvd_style:
        recmp_list = hvd_recmp_base.copy()

        if args.cpu:
            recmp_list.insert(2, hvd_recmp_cpu)
        elif args.gpu:
            recmp_list.insert(2, hvd_recmp_gpu)
        else:
            logging.warning("--hvd provided, but no --cpu/--gpu")

        if args.pattern_lst:
            recmp_list.extend(get_patterns_from_str(args.pattern_lst))

        parse_hvd_style(args.FILE, args.num_folds, recmp_list)

    if args.omb_style:
        if args.pattern_lst:
            recmp_list = get_patterns_from_str(args.pattern_lst)
        else:
            logging.error(
                "No pattern provided, use -p/--pattern_lst to pass in a comma sepperated list")

        parse_omb_style(args.FILE, recmp_list, omb_recmp_run,
                        num_folds=args.num_folds, fold_by=args.fold_by)


if __name__ == "__main__":
    main()
