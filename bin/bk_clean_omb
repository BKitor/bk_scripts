#!/usr/bin/python3
import clean_lib
import logging
import csv
import sys

import pprint
pp = pprint.PrettyPrinter()

'''
TODO: Will silently fail if not all experiment identifiers (string passed in
by `-p`) are matched. Should probably list which patterns are missing.
'''


def bk_chunk_list(lst, n):
    for i in range(0, len(lst), n):
        yield lst[i:i+n]


def get_exps_from_pattern_list(pattern_list):
    return [list(i.groupindex.keys())[0] for i in pattern_list]


def get_trials_from_parsed_data(parsed_data):
    verify_parse_dict_integrity(parsed_data)
    return [i for i in list(parsed_data.values())[0]]


def verify_parse_dict_integrity(parse_dict):
    exp_list = []
    for i in parse_dict.values():
        exp_list.append(list(i.keys()))
    for i in exp_list:
        if set(i) != set(exp_list[0]):
            logging.error(
                "exp_list set check failed, will continue with errors!!!")


def parse_omb_style_default(file_name, exp_pattern_arr, line_pattern):
    '''
    return 2 elements
    exp_names -> array of experiment names
    dat_dict -> dict for each message size to a dict of exp_name:time
    {"msize": {"exp_name" : "time" } }
    '''
    exp_name = ""
    dat_dict = {}
    exp_names = []
    track_matches_arr = [False for _ in exp_pattern_arr]
    with open(file_name) as f:
        for line in f:
            exp_matches = map(lambda x: x.search(line), exp_pattern_arr)
            m_dat = line_pattern.search(line)

            exp_match_list = list(exp_matches)

            if all(m is None for m in exp_match_list) and m_dat is None:
                continue

            for i, m in enumerate(exp_match_list):
                if m is None:
                    continue

                # the experiment matching shuold be thought thorugh a bit better tbh
                if track_matches_arr[i]:
                    logging.debug("Clearing exp_name")
                    track_matches_arr = [False for _ in exp_pattern_arr]
                    # if exp_name not in exp_names:
                    #     exp_names.append(exp_name)
                    exp_name = ""

                track_matches_arr[i] = True
                g_idx = exp_pattern_arr[i].groupindex

                for gname, idx in g_idx.items():
                    logging.debug(f"matched identifier {gname}:{m.group(idx)}")
                    exp_name += f"{gname}{m.group(idx)}_"

                if all(track_matches_arr) and exp_name not in exp_names:
                    logging.debug(f"adding {exp_name} to exp_names")
                    exp_names.append(exp_name)

            if m_dat is None:
                logging.debug(exp_names)
                continue

            if m_dat.group(1) not in dat_dict:
                dat_dict[m_dat.group(1)] = {}

            logging.debug(
                f"matched datapoint {m_dat.group(1)}:{m_dat.group(2)}")
            dat_dict[m_dat.group(1)][exp_name] = m_dat.group(2)

    return dat_dict


def print_exp_names_from_dat_dict(exp_names, dat_dict):
    # might want to cache this somewhere so that i'm not constatnly recalculating
    # point towards making this more class-based
    dat_arr = list(dat_dict.items())  # list of  ('msize', {'exp_name':'time'})
    dat_arr.sort(key=lambda x: int(x[0]))  # sort numericly by message size

    csv_headers = ["msize"]
    csv_headers.extend(exp_names)

    csv_writer = csv.DictWriter(sys.stdout, csv_headers)
    csv_writer.writeheader()

    for row in dat_arr:
        for exp_name in exp_names:  # error checking in case a run didn't complete
            if exp_name not in row[1]:
                row[1][exp_name] = None

        tmp_dict = {
            exp_name: row[1][exp_name] for exp_name in exp_names
        }
        tmp_dict["msize"] = row[0]
        csv_writer.writerow(tmp_dict)


def print_omb_by_num(num_folds, data_dict, dat_dict_type):
    trial_name_list = get_trials_from_parsed_data(data_dict)

    csv_w = csv.writer(sys.stdout) 

    for trials in bk_chunk_list(trial_name_list, num_folds):
        if dat_dict_type == "full":
            out_arr = ['msize']
            out_arr.extend(f"{t}avg_lat" for t in trials)
            out_arr.append("")
            out_arr.extend(f"{t}min_lat" for t in trials)
            out_arr.append("")
            out_arr.extend(f"{t}max_lat" for t in trials)
            csv_w.writerow(out_arr)
            for msize in data_dict:
                out_arr = [msize]
                out_arr.extend(data_dict[msize][t]["avg_lat"] for t in trials)
                out_arr.append("")
                out_arr.extend(data_dict[msize][t]["min_lat"] for t in trials)
                out_arr.append("")
                out_arr.extend(data_dict[msize][t]["max_lat"] for t in trials)
                csv_w.writerow(out_arr)
        else:
            out_arr = ['msize']
            out_arr.extend(trials)
            csv_w.writerow(out_arr)
            for msize in data_dict:
                out_arr = [msize]
                out_arr.extend(data_dict[msize][t] for t in trials)
                csv_w.writerow(out_arr)


def print_omb_by_group_v2(fold_exp, pattern_list, data_dict, dat_dict_type="default"):
    # valid types are "default" or "full"
    exp_list = get_exps_from_pattern_list(pattern_list)
    if fold_exp not in exp_list:
        logging.error(f"-g {fold_exp} not in -p {exp_list}")
        return

    group_dict = {}

    trial_name_list = get_trials_from_parsed_data(data_dict)
    for t in trial_name_list:
        e_start = t.find(fold_exp)
        e_end = t.find("_", e_start + len(fold_exp))
        group_str = t[e_start:e_end]

        if group_str not in group_dict:
            group_dict[group_str] = {msize: {} for msize in data_dict}

        for msize in data_dict:
            group_dict[group_str][msize][t] = data_dict[msize][t]

    for k in group_dict:
        num_trials_in_group = len(group_dict[k][list(group_dict[k])[0]])
        print_omb_by_num(num_trials_in_group, group_dict[k], dat_dict_type)


def parse_omb_full(file_name, pattern_list, data_line_pattern):
    # returns dict -> {'msize':{'exp_name':{"min", "max", "avg"}}}
    exp_keys = get_exps_from_pattern_list(pattern_list)
    cur_exp_dict = {i: "" for i in exp_keys}
    ret_dict = {}

    def _build_exp_str(_exp_dict):
        _tmp_str = ""
        for k in _exp_dict:
            _tmp_str += f"{k}{_exp_dict[k]}_"
        return _tmp_str

    with open(file_name) as f:
        for line in f:
            l_m = data_line_pattern.search(line)
            exp_matches = map(lambda x: x.search(line), pattern_list)

            if l_m:
                cur_exp = _build_exp_str(cur_exp_dict)
                msize = l_m["msize"]
                if msize not in ret_dict:
                    ret_dict[msize] = {}
                if cur_exp not in ret_dict[msize]:
                    ret_dict[msize][cur_exp] = {}

                ret_dict[msize][cur_exp]["avg_lat"] = l_m["avg_lat"]
                ret_dict[msize][cur_exp]["max_lat"] = l_m["max_lat"]
                ret_dict[msize][cur_exp]["min_lat"] = l_m["min_lat"]
                continue

            for m in exp_matches:
                if m is None:
                    continue

                m_gd = m.groupdict()
                for k in m_gd:
                    cur_exp_dict[k] = m_gd[k]

    return ret_dict


def main():
    args = clean_lib.parse_inputs()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    pattern_list = clean_lib.get_patterns_from_str(
        args.pattern_lst) if args.pattern_lst else []

    omb_output_type = "default" if not args.omb_full else "full"
    data_line_pattern = clean_lib.omb_patters[omb_output_type]

    if args.omb_full:
        file_parse_dict = parse_omb_full(args.FILE, pattern_list,
                                         data_line_pattern)
    else:
        file_parse_dict = parse_omb_style_default(
            args.FILE, pattern_list, data_line_pattern)

    if not file_parse_dict:
        logging.error("file parse dict is empty, check if --omb_full is set")
        return

    if args.group_by:
        print_omb_by_group_v2(args.group_by, pattern_list,
                              file_parse_dict, omb_output_type)
    elif args.num_folds:
        print_omb_by_num(args.num_folds,
                         file_parse_dict, omb_output_type)


if __name__ == "__main__":
    main()
